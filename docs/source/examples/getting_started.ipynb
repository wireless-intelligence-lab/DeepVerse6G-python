{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with DeepVerse6G\n",
    "\n",
    "DeepVerse 6G is a multi-modal wireless dataset providing diverse sensory information, including LiDAR, radar, and camera data. It complements digital twin data offered by the [DeepSense 6G dataset](www.deepsense6g.net), enabling comprehensive research and development in 6G technologies.\n",
    "\n",
    "DeepVerse 6G is designed to facilitate research in several key areas, including:\n",
    "\n",
    "*   **Wireless Communications and Sensing:** The dataset can be used to study channel propagation characteristics, evaluate communication protocols, and develop advanced signal processing techniques. The combination of sensor data and communication information allows for the exploration of integrated sensing and communication (ISAC) techniques.\n",
    "*   **Digital Twins:**  By integrating with the DeepSense 6G dataset, researchers can create and evaluate digital twins of real-world environments, enabling virtualized testing and optimization of 6G systems.\n",
    "*   **Machine Learning:** The large and diverse dataset is well-suited for training and evaluating machine learning models for various tasks, such as object detection, scene understanding, and predictive maintenance.\n",
    "\n",
    "Key features of DeepVerse 6G include:\n",
    "\n",
    "*   **Multi-Modality:**  The dataset provides synchronized data from multiple sensors (LiDAR, radar, camera), enabling comprehensive scene understanding.\n",
    "*   **Parametric Generation:**  The dataset can be generated parametrically, allowing researchers to customize the scenarios and sensor configurations to match their specific needs.  This includes control over aspects of the wireless channel, sensor placement, and environment complexity.\n",
    "*   **Digital Twins:**  The real-world data collection based (DeepSense 6G dataset)[www.deepsense6g.net] enables the creation and analysis of digital twins.\n",
    "*   **Realistic Scenarios:** The dataset is designed to simulate realistic urban and other environments, providing a valuable testbed for 6G technologies.\n",
    "\n",
    "This notebook will guide you through the process of using DeepVerse 6G, covering topics such as:\n",
    "\n",
    "*   Setting up the DeepVerse 6G environment.\n",
    "*   Configuring the dataset parameters.\n",
    "*   Loading and accessing the sensor data.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the required modules of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deepverse import ParameterManager\n",
    "from deepverse import Dataset\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset\n",
    "\n",
    "The DeepVerse 6G dataset comprises of scenarios and the generator (the DeepVerse 6G library)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenarios\n",
    "\n",
    "The DeepVerse 6G dataset comprises of scenarios. Each scenario is a virtual environment where different sensors and wireless modality data generated. These scenarios are available at [scenarios page](www.deepverse6g.net/scenarios). Some example scenarios can be summarized as follows:\n",
    "- [**Carla Town1**](link): Summary to be added.\n",
    "- [**Digital Twin**](link): Summary to be added..\n",
    "- [**Outdoor 1**](link): Summary to be added..\n",
    "- [**Indoor 1**](link): Summary to be added..\n",
    "\n",
    "To generate the data of a scenario, we need to download files of a desired scenario from the corresponding webpage. Then, these scenarios can be placed in a path `../dataset_folder/scenario_name`. After this operation is completed, we can generate our data using the DeepVerse6G generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Dataset\n",
    "\n",
    "#### Setting the Parameters\n",
    "For the parametric generation of DeepVerse, we first need to set the parameters to generate a dataset. Let's load the `.m` parameter file and check them. In this example, we load `config.m` in `params` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Parameters:\n",
      "{'basestations': [1],\n",
      " 'camera': True,\n",
      " 'camera_id': [1, 2, 3, 4, 5],\n",
      " 'comm': {'OFDM': {'bandwidth': 0.05,\n",
      "                   'selected_subcarriers': [0, 1],\n",
      "                   'subcarriers': 512},\n",
      "          'activate_RX_filter': 0,\n",
      "          'bs_antenna': {'FoV': [360, 180],\n",
      "                         'rotation': [5, 10, 20],\n",
      "                         'shape': [32, 1],\n",
      "                         'spacing': 0.5},\n",
      "          'enable': True,\n",
      "          'enable_Doppler': 1,\n",
      "          'generate_OFDM_channels': 1,\n",
      "          'num_paths': 25,\n",
      "          'ue_antenna': {'FoV': [360, 180],\n",
      "                         'rotation': [0, 30, 0],\n",
      "                         'shape': [1, 1],\n",
      "                         'spacing': 0.5}},\n",
      " 'dataset_folder': 'D:\\\\\\\\DeepVerse\\\\\\\\scenarios',\n",
      " 'lidar': True,\n",
      " 'position': True,\n",
      " 'radar': {'FMCW': {'Fs': 4000000.0,\n",
      "                    'chirp_slope': 15000000000000.0,\n",
      "                    'n_chirps': 256,\n",
      "                    'n_samples_per_chirp': 512},\n",
      "           'enable': False,\n",
      "           'num_paths': 5000,\n",
      "           'rx_antenna': {'FoV': [360, 180],\n",
      "                          'rotation': [0, 0, -90],\n",
      "                          'shape': [32, 1],\n",
      "                          'spacing': 0.5},\n",
      "           'tx_antenna': {'FoV': [360, 180],\n",
      "                          'rotation': [0, 0, -90],\n",
      "                          'shape': [1, 1],\n",
      "                          'spacing': 0.5}},\n",
      " 'scenario': 'Town01-Carla',\n",
      " 'scenes': [100, 101]}\n"
     ]
    }
   ],
   "source": [
    "# Path to the MATLAB configuration file\n",
    "config_path = os.path.join(\"../params/config.m\")\n",
    "\n",
    "# Initialize ParameterManager and load parameters\n",
    "param_manager = ParameterManager(config_path)\n",
    "\n",
    "# # Print the loaded parameters\n",
    "print(\"Loaded Parameters:\")\n",
    "pprint(param_manager.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the specifics of the various configuration parameters (which will be covered in detail in subsequent notebooks), let's focus on generating a DeepVerse dataset.  Two essential parameters must be set for this initial step: `dataset_folder` and `scenario`.\n",
    "\n",
    "*   **`dataset_folder`:** This parameter specifies the main directory containing all your scenario data.  For example: `../scenarios/` (note the trailing slash).  This folder will contain subfolders, each representing a different scenario.\n",
    "\n",
    "*   **`scenario`:** This parameter indicates the specific scenario you want to generate.  It should correspond to the name of a subfolder *within* the `dataset_folder`.  For example, if your `dataset_folder` is `../scenarios/` and you have a subfolder named `Town01-Carla` containing the scenario data, then `scenario` should be set to `Town01-Carla`.\n",
    "\n",
    "By correctly configuring these two parameters, DeepVerse 6G knows where to find the scenario data and which scenario to load/generate.  The combination of `dataset_folder` and `scenario` effectively points to the specific dataset you want to work with.  The remaining parameters, which we'll explore later, will allow you to fine-tune the generation process and customize the dataset further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll configure these parameters at runtime to specify the locations of our scenario data: (this can also be done by editing `config.m` file before loading the parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_manager.params['dataset_folder'] = r'D:\\DeepVerse\\scenarios'\n",
    "param_manager.params['scenario'] = 'Town01-Carla'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generation Process\n",
    "\n",
    "The DeepVerse 6G dataset generation process involves real-time generation of wireless communication and radar data. Other sensor data (e.g., camera, LiDAR) is loaded directly into the dataset object.\n",
    "\n",
    "After setting the necessary parameters, we initialize the DeepVerse dataset object to trigger the data generation, using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\n",
      "Scene 1/2\n",
      "\n",
      "Basestation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Generating channels: 100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/2\n",
      "\n",
      "Basestation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Generating channels: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 1/2\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Generating channels: 100%|██████████| 2/2 [00:00<00:00, 1001.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Generating channels: 100%|██████████| 1/1 [00:00<00:00, 250.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/2\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Generating channels: 100%|██████████| 2/2 [00:00<00:00, 1998.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Generating channels: 100%|██████████| 1/1 [00:00<00:00, 250.14it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(param_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Data Modalities\n",
    "\n",
    "The generated DeepVerse 6G dataset can be accessed by modality.  The following sections provide the commands for retrieving data from each sensor type:\n",
    "\n",
    "*   Wireless\n",
    "*   LiDAR\n",
    "*   Radar\n",
    "*   Camera\n",
    "\n",
    "Further notebooks will provide in-depth explorations of each modality's capabilities and data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepVerse\\scenarios\\Town01-Carla\\RGB_images\\cam1\\2.jpg\n"
     ]
    }
   ],
   "source": [
    "camera_sample = dataset.get_sample('cam', index=2, device_index=1)  # Get sample from camera 1\n",
    "print(camera_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepVerse\\scenarios\\Town01-Carla\\lidar\\bs2\\5.pcd\n"
     ]
    }
   ],
   "source": [
    "# Example of retrieving specific samples and visualizing them (assuming Dataset methods are defined)\n",
    "lidar_sample = dataset.get_sample('lidar', index=5, device_index=1)  # Get sample from LiDAR 1\n",
    "print(lidar_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMCW Radar Waveform: 256 chirps, 512 samples/chirp, slope: 15.000 THz/s, sampling: 4.000 MHz, chirp duration: 128.000 µs,BW: 1.920 GHz\n",
      "Antenna - Size: [1, 1] Rot: [  0   0 -90] FoV: [360, 180] Spacing: 0.5\n",
      "Antenna - Size: [32, 1] Rot: [  0   0 -90] FoV: [360, 180] Spacing: 0.5\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "radar_sample = dataset.get_sample('radar', index=1, bs_idx=0, ue_idx=0)\n",
    "# There is no UE, it is the bs_tx_idx=bs_idx and bs_rx_idx=ue_idx\n",
    "# Channel can be reached with:\n",
    "# radar_sample.coeffs\n",
    "# ------- Some print examples ----------\n",
    "# print(radar_sample)\n",
    "# print(radar_sample.paths)\n",
    "print(radar_sample.waveform)\n",
    "print(radar_sample.tx_antenna)\n",
    "print(radar_sample.rx_antenna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wireless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Channels from Basestations to Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel sample shape (32, 1, 2)\n",
      "Antenna - Size: [32, 1] Rot: [ 5 10 20] FoV: [360, 180] Spacing: 0.5\n",
      "Antenna - Size: [1, 1] Rot: [ 0 30  0] FoV: [360, 180] Spacing: 0.5\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "comm_sample = dataset.get_sample('comm-ue', index=1, bs_idx=0, ue_idx=1)\n",
    "# Channel can be reached with:\n",
    "# comm_sample.coeffs\n",
    "print('Channel sample shape', comm_sample.coeffs.shape)\n",
    "\n",
    "# ------- Some print examples ----------\n",
    "# print(comm_sample)\n",
    "# print(comm_sample.paths)\n",
    "# print(comm_sample.LoS_status)\n",
    "print(comm_sample.tx_antenna)\n",
    "print(comm_sample.rx_antenna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Channels from Basestations to Basestations\n",
    "- may be used for interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel sample shape (32, 32, 2)\n",
      "Antenna - Size: [32, 1] Rot: [ 5 10 20] FoV: [360, 180] Spacing: 0.5\n",
      "Antenna - Size: [32, 1] Rot: [ 5 10 20] FoV: [360, 180] Spacing: 0.5\n"
     ]
    }
   ],
   "source": [
    "#%% For interference channels and various applications, basestation to basestation channels can be obtained as follows:\n",
    "comm_bs2bs_sample = dataset.get_sample('comm-bs', index=1, bs_idx=0, ue_idx=0) \n",
    "\n",
    "# Channel can be reached with:\n",
    "# comm_bs2bs_sample.coeffs\n",
    "print('Channel sample shape', comm_bs2bs_sample.coeffs.shape)\n",
    "\n",
    "# ------- Some print examples ----------\n",
    "# print(comm_bs2bs_sample)\n",
    "# print(comm_bs2bs_sample.paths)\n",
    "# print(comm_bs2bs_sample.LoS_status)\n",
    "print(comm_bs2bs_sample.tx_antenna)\n",
    "print(comm_bs2bs_sample.rx_antenna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "location = dataset.get_sample('loc', index=1, ue_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mobility (Moving Objects - Vehicles, Humans etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: MovingObject(id=0, num_time_samples=417, time_interval=40,456),\n",
      " 1: MovingObject(id=1, num_time_samples=312, time_interval=100,411),\n",
      " 2: MovingObject(id=2, num_time_samples=314, time_interval=250,563),\n",
      " 3: MovingObject(id=3, num_time_samples=315, time_interval=330,644),\n",
      " 4: MovingObject(id=4, num_time_samples=315, time_interval=354,668),\n",
      " 5: MovingObject(id=5, num_time_samples=317, time_interval=420,736),\n",
      " 6: MovingObject(id=6, num_time_samples=312, time_interval=450,761),\n",
      " 7: MovingObject(id=7, num_time_samples=423, time_interval=482,904),\n",
      " 8: MovingObject(id=8, num_time_samples=415, time_interval=500,914),\n",
      " 9: MovingObject(id=9, num_time_samples=315, time_interval=519,833),\n",
      " 10: MovingObject(id=10, num_time_samples=334, time_interval=530,863),\n",
      " 11: MovingObject(id=11, num_time_samples=311, time_interval=538,848),\n",
      " 12: MovingObject(id=12, num_time_samples=320, time_interval=570,889),\n",
      " 13: MovingObject(id=13, num_time_samples=331, time_interval=570,900),\n",
      " 14: MovingObject(id=14, num_time_samples=323, time_interval=600,922),\n",
      " 15: MovingObject(id=15, num_time_samples=322, time_interval=610,931),\n",
      " 16: MovingObject(id=16, num_time_samples=419, time_interval=632,1050),\n",
      " 17: MovingObject(id=17, num_time_samples=420, time_interval=690,1109),\n",
      " 18: MovingObject(id=18, num_time_samples=419, time_interval=692,1110),\n",
      " 19: MovingObject(id=19, num_time_samples=315, time_interval=729,1043),\n",
      " 20: MovingObject(id=20, num_time_samples=422, time_interval=770,1191),\n",
      " 21: MovingObject(id=21, num_time_samples=315, time_interval=807,1121),\n",
      " 22: MovingObject(id=22, num_time_samples=415, time_interval=830,1244),\n",
      " 23: MovingObject(id=23, num_time_samples=322, time_interval=832,1153),\n",
      " 24: MovingObject(id=24, num_time_samples=319, time_interval=890,1208),\n",
      " 25: MovingObject(id=25, num_time_samples=314, time_interval=890,1203),\n",
      " 26: MovingObject(id=26, num_time_samples=414, time_interval=990,1403),\n",
      " 27: MovingObject(id=27, num_time_samples=313, time_interval=1070,1382),\n",
      " 28: MovingObject(id=28, num_time_samples=316, time_interval=1120,1435),\n",
      " 29: MovingObject(id=29, num_time_samples=418, time_interval=1170,1587),\n",
      " 30: MovingObject(id=30, num_time_samples=312, time_interval=1260,1571),\n",
      " 31: MovingObject(id=31, num_time_samples=420, time_interval=1270,1689),\n",
      " 32: MovingObject(id=32, num_time_samples=313, time_interval=1340,1652),\n",
      " 33: MovingObject(id=33, num_time_samples=320, time_interval=1370,1689),\n",
      " 34: MovingObject(id=34, num_time_samples=313, time_interval=1390,1702),\n",
      " 35: MovingObject(id=35, num_time_samples=420, time_interval=1430,1849),\n",
      " 36: MovingObject(id=36, num_time_samples=313, time_interval=1470,1782),\n",
      " 37: MovingObject(id=37, num_time_samples=419, time_interval=1550,1968),\n",
      " 38: MovingObject(id=38, num_time_samples=316, time_interval=1560,1875),\n",
      " 39: MovingObject(id=39, num_time_samples=316, time_interval=1588,1903),\n",
      " 40: MovingObject(id=40, num_time_samples=390, time_interval=1610,1999),\n",
      " 41: MovingObject(id=41, num_time_samples=317, time_interval=1630,1946),\n",
      " 42: MovingObject(id=42, num_time_samples=316, time_interval=1649,1964),\n",
      " 43: MovingObject(id=43, num_time_samples=315, time_interval=1680,1994),\n",
      " 44: MovingObject(id=44, num_time_samples=220, time_interval=1780,1999),\n",
      " 45: MovingObject(id=45, num_time_samples=200, time_interval=1800,1999),\n",
      " 46: MovingObject(id=46, num_time_samples=160, time_interval=1840,1999),\n",
      " 47: MovingObject(id=47, num_time_samples=90, time_interval=1910,1999)}\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "mobility = dataset.get_sample('mobility', index=1, ue_idx=0)\n",
    "pprint(mobility)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gui-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
